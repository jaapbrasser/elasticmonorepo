{
    "title": "Examples of Questions to Ask About Elasticsearch",
    "systemMessage": "You are a helpful assistant for Elasticsearch. Your goal is to help Elasticsearch users accomplish tasks using Kibana and Elasticsearch. You can help them construct queries, index data, search data, use Elasticsearch APIs, generate sample data, visualise and analyze data.\n\n  It's very important to not assume what the user means. Ask them for clarification if needed.\n\n  If you are unsure about which function should be used and with what arguments, ask the user for clarification or confirmation.\n\n  In KQL (\"kqlFilter\")) escaping happens with double quotes, not single quotes. Some characters that need escaping are: ':()\\  /\". Always put a field value in double quotes. Best: service.name:\"opbeans-go\". Wrong: service.name:opbeans-go. This is very important!\n\n  You can use Github-flavored Markdown in your responses. If a function returns an array, consider using a Markdown table to format the response.\n\n  Note that the Elasticsearch query DSL is the preferred language. Do not use ES|QL.\n\n  If you want to call a function or tool, only call it a single time per message. Wait until the function has been executed and its results\n  returned to you, before executing the same tool or another tool again if needed.\n\n  The user is able to change the language which they want you to reply in on the settings page of the AI Assistant for Observability and Search, which can be found in the Stack Management app under the option AI Assistants.\n  If the user asks how to change the language, reply in the same language the user asked in.\n\n<QueryLanguages>\n\n\n*  **KQL Usage:** Use KQL *only* when specified by the user or context requires it (e.g., filtering in specific older UIs if applicable, though ES|QL is generally forward-looking).\n*  **Strict Syntax Separation:**\n    *   **ES|QL:** Uses syntax like `service.name == \"foo\"`.\n    *   **KQL (`kqlFilter` parameter):** Uses syntax like `service.name:\"foo\"`. **Crucially**, values in KQL filters **MUST** be enclosed in double quotes (`\"`). Characters like `:`, `(`, `)`, `\\`, `/`, `\"` within the value also need escaping.\n    \n*  **Delegate ES|QL Tasks to the `query` tool:**\n    *   You **MUST** use the `query` tool for *all* tasks involving ES|QL, including: generating, visualizing (preparing query for), running, breaking down, filtering, converting, explaining, or correcting ES|QL queries.\n    *   **DO NOT** generate, explain, or correct ES|QL queries yourself. Always delegate to the `query` tool, even if it was just used or if it previously failed.\n    *   If `get_dataset_info` return no results, but the user asks for a query, *still* call the `query` tool to generate an *example* query based on the request.\n* When a user requests paginated results using ES|QL (e.g., asking for a specific page or part of the results), you must inform them that ES|QL does not support pagination or offset. Clearly explain that only limiting the number of results (using LIMIT) is possible, and provide an example query that returns the first N results. Do not attempt to simulate pagination or suggest unsupported features. Always clarify this limitation in your response.\n* When converting queries from another language (e.g SPL, LogQL, DQL) to ES|QL, generate functionally equivalent ES|QL query using the available index and field information. Infer the indices and fields from the user's query and always call `query` tool to provide a **valid and functionally equivalent** example ES|QL query. Always clarify any field name assumptions and prompt the user for clarification if necessary.\n* **Critical ES|QL syntax rules:**\n    * When using `DATE_FORMAT`, any literal text in the format string **MUST** be in single quotes. Example: `DATE_FORMAT(\"d 'of' MMMM yyyy\", @timestamp)`.\n    * When grouping with `STATS`, use the field name directly. Example: `STATS count = COUNT(*) BY destination.domain`.\n\n</QueryLanguages>\n\n\n<FunctionUsageGuidelines>\n\n**Get Dataset Information:** Use the `get_dataset_info` tool to get information about indices/datasets available and the fields available on them. \n         * Providing an empty string as index name will retrieve all indices. Otherwise list of all fields for the given index will be given.\n         * If the user doesn't specify a particular index, always retrieve all indices.\n         * If no fields are returned this means no indices were matched by provided index pattern. \n         * Wildcards can be part of index name.\n\n**Always use the `get_dataset_info` tool to get information about indices/datasets available and the fields and field types available on them instead of using Elasticsearch APIs directly.**\n\n**Prerequisites for the `query` tool:** Before calling the `query` tool, you **SHOULD ALWAYS** first call `get_dataset_info` to discover indices, data streams and fields. These instructions better describe the process:\n        * When to fetch dataset info:\n         * Do it once per dataset. Re-use previously fetched dataset information unless the user asks about new data.\n         * If you identify indices to query in the response of `get_dataset_info` tools which matches the user's question, **ALWAYS** use those index/indices to generate the query.\n         * Skip it only when the user already supplied a complete query that includes a valid `FROM <index>` clause in the query.\n         * Skip it if the user asks you to **assume** their data is in a particular index in their question.\n        * For example queries and syntax conversion requests:\n          * If the user doesn't ask for specific data, but rather asks for the query, you can consider it an example query in this context. \n          * If dataset lookup yields nothing, you **MUST** still call `query`\n          * Make a sensible index and field assumptions from the user's request. Notify the user of the assumptions you used.\n          * Do **NOT** ask them to supply index or field names first.\n        * If dataset info is missing *after* the lookup and the request is not an example or syntax conversion, ask the user which index / data stream or fields to use **before** calling `query`.\n     \n\n**Elastic Stack Questions:** For general questions about Elastic Stack products or features, ideally use the dedicated `retrieve_elastic_doc` tool. Consider that the documentation returned by this tool is always more up to date and accurate than any own internal knowledge you might have.\n\n**Summarization and Memory:** You **MUST** use the `summarize` tool to save information for long-term use. Follow these steps:\n          * **Listen for Keywords:** Use this tool **only** when the user explicitly says phrases like \"remember,\" \"store,\" \"save,\" or \"keep\" information.\n          * **Understand the Goal:** This function creates a permanent memory that can be accessed in future conversations.\n          * **Take Action:** When you detect a keyword, your primary action is to call the `summarize` tool. Do not just say that you will remember something.\n          * **Language:** All summaries **MUST** be generated in English.\n\n**Context Retrieval:** You can use the `context` tool to retrieve relevant information from the knowledge database. The response will include a \"learnings\" field containing information\n          from the knowledge base that is most relevant to the user's current query. You should incorporate these learnings into your responses when answering the user's questions.\n          The information in the \"learnings\" field contains up-to-date information that you should consider when formulating your responses. DO NOT add disclaimers about the currency or certainty of this information.\n          Present this information directly without qualifiers like \"I don't have specific, up-to-date information\" or \"I can't be completely certain\".\n          \n          Stick strictly to the information provided in the \"learnings\" field. DO NOT assume, infer, or add any details that are not explicitly stated in the response.\n          If the user asks for information that is not covered in the \"learnings\" field, acknowledge the gap and ask for clarification rather than making assumptions or offering suggestions that aren't based on the provided knowledge.\n\n**Elasticsearch API:** Use the `elasticsearch` tool to call Elasticsearch APIs on behalf of the user\n\n           * **When to use:** Whenever the user asks for information or an action that maps directly to an Elasticsearch REST API **(e.g. cluster health, license, index statistics, index creation, adding documents, etc.)** you **MUST** call the `elasticsearch` tool. You have to derive which endpoint to call without explicitly asking the user. **NEVER** ask for permission to proceed with GET requests. You **MUST** call the `elasticsearch` tool with the appropriate method and path. You are only allowed to perform GET requests and GET/POST requests for the `/_search` endpoint (for search operations). For POST `/_search` operations, if a request body is needed, make sure the request body is a valid object.\n\n           * **Disallowed actions:** If the user asks to perform destructive actions or actions that are not allowed (e.g. PUT, PATCH, DELETE requests or POST requests that are not to the `/_search` endpoint), **NEVER** attempt to call the elasticsearch tool. Instead, inform the user that you do not have the capability to perform those actions.\n           * **Path parameter tips:** When requesting index stats, append the **specific path paramater** to the API endpoint if the user mentions it (example: `{index}/_stats/store` for *store stats*) instead of the generic `{index}/_stats`. Always populate the path with the index name if the user is referring to a specific index.\n\n           * **Follow-up requests:** If the user subsequently asks for more information about an index **without explicitly repeating the index name**, ALWAYS assume they mean the **same index you just used** in the prior Elasticsearch call and build the path accordingly. Do **not** ask the user to re-state the index name in such follow-up questions.\n\n</FunctionUsageGuidelines>\n\n\n<UserInteraction>\n\n  **Language Settings:** If the user asks how to change the language, explain that it's done in the AI Assistant settings within Stack Management, replying in the *same language* the user asked in.\n\n</UserInteraction>",
    "messages": [
        {
            "@timestamp": "2026-01-10T09:56:45.404Z",
            "message": {
                "role": "user",
                "content": "Give me examples of questions I can ask here."
            }
        },
        {
            "@timestamp": "2026-01-10T09:56:45.807Z",
            "message": {
                "role": "assistant",
                "function_call": {
                    "name": "context",
                    "trigger": "assistant"
                },
                "content": ""
            }
        },
        {
            "@timestamp": "2026-01-10T09:56:47.258Z",
            "message": {
                "role": "user",
                "data": {
                    "llmScores": [],
                    "suggestions": []
                },
                "name": "context",
                "content": {
                    "screen_description": "The user is looking at https://7f6693b2143d448880d187fef7b5e298.us-central1.gcp.cloud.es.io/app/search_playground. The current time range is 2026-01-10T09:39:45.776Z - 2026-01-10T09:54:45.776Z.",
                    "learnings": []
                }
            }
        },
        {
            "@timestamp": "2026-01-10T09:56:55.948Z",
            "message": {
                "role": "assistant",
                "function_call": {
                    "name": "",
                    "arguments": "",
                    "trigger": "assistant"
                },
                "content": "# Questions You Can Ask\n\nHere are some examples of questions you can ask me about Elasticsearch and Kibana:\n\n## Querying Data\n- \"How do I search for documents containing the word 'error' in my logs?\"\n- \"Create a query to find transactions with amounts greater than $1000\"\n- \"Help me write an ES|QL query to find failed login attempts\"\n- \"How can I convert this Splunk query to ES|QL: `source=web_logs status=404 | stats count by url`?\"\n- \"Show me how to use aggregations to find the top 5 users by activity\"\n\n## Data Exploration\n- \"What indices do I have in my cluster?\"\n- \"Show me the fields available in my logs-* indices\"\n- \"What's the health of my Elasticsearch cluster?\"\n- \"How many documents are in my transactions index?\"\n- \"Help me analyze response time trends in my web logs\"\n\n## Elasticsearch Administration\n- \"How do I check my cluster health?\"\n- \"What's the status of my shards?\"\n- \"Show me how to create a new index with custom mappings\"\n- \"How do I set up an index lifecycle policy?\"\n- \"What's the current license status of my cluster?\"\n\n## Kibana Features\n- \"How do I create a dashboard in Kibana?\"\n- \"What visualization types are available in Kibana?\"\n- \"How can I set up alerts for high CPU usage?\"\n- \"Help me understand how to use Kibana Lens\"\n- \"How do I save and share my searches in Kibana?\"\n\n## Learning Resources\n- \"Explain how ES|QL works\"\n- \"What's the difference between KQL and ES|QL?\"\n- \"Tell me about Elasticsearch's relevance scoring\"\n- \"How do I optimize my Elasticsearch queries?\"\n- \"Explain the concept of document routing in Elasticsearch\"\n\nFeel free to ask any of these questions or formulate your own based on what you need help with regarding Elasticsearch and Kibana!"
            }
        },
        {
            "@timestamp": "2026-01-10T09:58:06.722Z",
            "message": {
                "role": "user",
                "content": "What's the difference between KQL and ES|QL?"
            }
        },
        {
            "@timestamp": "2026-01-10T09:58:07.094Z",
            "message": {
                "role": "assistant",
                "function_call": {
                    "name": "context",
                    "trigger": "assistant"
                },
                "content": ""
            }
        },
        {
            "@timestamp": "2026-01-10T09:58:08.481Z",
            "message": {
                "role": "user",
                "data": {
                    "llmScores": [],
                    "suggestions": []
                },
                "name": "context",
                "content": {
                    "screen_description": "The user is looking at https://7f6693b2143d448880d187fef7b5e298.us-central1.gcp.cloud.es.io/app/search_playground. The current time range is 2026-01-10T09:39:45.776Z - 2026-01-10T09:54:45.776Z.",
                    "learnings": []
                }
            }
        },
        {
            "@timestamp": "2026-01-10T09:58:10.325Z",
            "message": {
                "role": "assistant",
                "function_call": {
                    "name": "retrieve_elastic_doc",
                    "arguments": {
                        "query": "Difference between KQL and ES|QL"
                    },
                    "trigger": "assistant"
                },
                "content": ""
            }
        },
        {
            "@timestamp": "2026-01-10T09:58:10.717Z",
            "message": {
                "role": "user",
                "name": "retrieve_elastic_doc",
                "content": {
                    "documents": [
                        {
                            "title": "ES",
                            "url": "https://www.elastic.co/docs/solutions/search/esql-for-search",
                            "content": "# ES|QL for search\n\nThis page provides an overview of how to use ES|QL for search use cases.\n<tip>\n  For a hands-on tutorial check out [Search and filter with ES|QL](https://www.elastic.co/docs/reference/query-languages/esql/esql-search-tutorial).\n</tip>\n\n## ES|QL search quick reference\n\nThe following table summarizes the key search features available in [ES|QL](https://www.elastic.co/docs/reference/query-languages/esql) and when they were introduced, organized chronologically by release.\n\n| Feature                                                                        | Description                                                               | Available since |\n|--------------------------------------------------------------------------------|---------------------------------------------------------------------------|-----------------|\n| [Match function/operator](#match-function-and-operator)Match function/operator | Perform basic text searches with `MATCH` function or match operator (`:`) | 8.17            |\n| [Query string function](#query-string-qstr-function)Query string function      | Execute complex queries with `QSTR` using Query String syntax             | 8.17            |\n| [Relevance scoring](#esql-for-search-scoring)Relevance scoring                 | Calculate and sort by relevance with `METADATA _score`                    | 8.18/9.0        |\n| [Semantic search](#semantic-search)Semantic search                             | Perform semantic searches on `semantic_text` field types                  | 8.18/9.0        |\n| [Hybrid search](#hybrid-search)Hybrid search                                   | Combine lexical and semantic search approaches with custom weights        | 8.18/9.0        |\n| [Kibana Query Language](#kql-function)Kibana Query Language                    | Use Kibana Query Language with the `KQL` function                         | 8.18/9.0        |\n| [Match phrase function](#match_phrase-function)Match phrase function           | Perform phrase matching with `MATCH_PHRASE` function                      | 8.19/9.1        |\n\n## How search works in ES|QL\n\nES|QL provides two distinct approaches for finding documents: filtering and searching. Understanding the difference is crucial for building effective queries and choosing the right approach for your use case.\n\n\nUnderstanding the difference is crucial for building effective queries and choosing the right approach for your use case.\n**Filtering** removes documents that don't meet your criteria. It's a binary yes/no decision - documents either match your conditions or they don't. Filtering is faster because it doesn't calculate relevance scores and leverages efficient index structures for exact matches, ranges, and boolean logic.\n**Searching** both filters documents and ranks them by relevance. It calculates a score for each matching document based on how well the content matches your query, allowing you to sort results from most relevant to least relevant. Search functions use advanced text analysis including stemming, synonyms, and fuzzy matching.\n**When to choose filtering:**\n- Exact category matches (`category.keyword == \"Electronics\"`)\n- Date ranges (`date >= \"2023-01-01\"`)\n- Numerical comparisons (`price < 100`)\n- Any scenario where you want all matching results without ranking\n\n**When to choose searching:**\n- Text queries where some results are more relevant than others\n- Finding documents similar to a search phrase\n- Any scenario where you want the \"best\" matches first\n- You want to use [analyzers](https://www.elastic.co/docs/reference/elasticsearch/mapping-reference/analyzer) or [synonyms](https://www.elastic.co/docs/solutions/search/full-text/search-with-synonyms)\n\nES|QL's search functions address several key limitations that existed for text filtering: they work directly on multivalued fields, leverage analyzers for proper text analysis, and use optimized Lucene index structures for better performance.\n\n### Relevance scoring\n\n\n\n\nTo get relevance-ranked results, you must explicitly request scoring with `METADATA _score` and sort by the score. Without this, even search functions like `MATCH` will only filter documents without ranking them.\n**Without `METADATA _score`**: All operations are filtering-only, even `MATCH`, `QSTR`, and `KQL` functions. Documents either match or don't match - no ranking occurs.\n**With `METADATA _score`**: [Search functions](https://www.elastic.co/docs/reference/query-languages/esql/functions-operators/search-functions) contribute to relevance scores, while filtering operations (range conditions, exact matches) don't affect scoring. You must explicitly use `SORT _score DESC` to see the most relevant results first.\nThis gives you full control over when to use fast filtering versus slower but more powerful relevance-based searching.\n\n## Search functions\n\nThe following functions provide text-based search capabilities in ES|QL with different levels of precision and control.\n\n### `MATCH` function and operator\n\nES|QL offers two syntax options for match, which replicate the functionality",
                            "summarized": true
                        },
                        {
                            "title": "Use ES",
                            "url": "https://www.elastic.co/docs/explore-analyze/query-filter/languages/esql-kibana",
                            "content": "# Use ES|QL in the Kibana UI\n\nYou can use [Elasticsearch query language (ES|QL)](https://www.elastic.co/docs/reference/query-languages/esql/esql-syntax-reference) in Kibana to query and aggregate your data, create visualizations, and set up alerts.\nThis page guides you through the basics of working with ES|QL in the Kibana UI.\nES|QL is tightly integated with Elastic solutions:\n- **Observability**  \n  - Query metrics, logs, and traces simultaneously\n  - Define fields dynamically, enrich data with lookups, and process queries in parallel\n  - Integrate with machine learning and AiOps for improved detection accuracy using aggregated thresholds\n- **Security**  \n  - Enrich investigation data with lookups and dynamic field creation\n  - Perform IP geolocation, threat intelligence, and cloud provider identification from a single query\n  - Use aggregated values in detection rules for more accurate alerts\n  - Find more details and examples in [ES|QL for Elastic Security use cases](https://www.elastic.co/docs/solutions/security/esql-for-security)\n\n<tip>\n  Find the complete list of supported commands, functions, and operators in the [ES|QL reference](https://www.elastic.co/docs/reference/query-languages/esql/esql-syntax-reference).\n</tip>\n\n## Load sample data\n\nTo run the queries in this guide in the Kibana UI, you must load the \"Sample web logs\" sample data set. Follow these steps:\n1. Select **Sample Data** from the **Integrations** page in Kibana\n2. Select **Other sample data sets**\n3. Click **Add data** on the **Sample web logs** card\n\n## Enable or disable ES|QL\n\n\n\n\nES|QL is enabled by default in Kibana. It can be disabled using the `enableESQL` setting from the [Advanced Settings](https://www.elastic.co/docs/reference/kibana/advanced-settings).\nThis will hide the ES|QL user interface from various applications. However, users will be able to access existing ES|QL artifacts like saved searches and visualizations.\n\n## The ES|QL editor\n\nTo get started with ES|QL, go to **Discover**. Next, select **Try ESQL** from the application menu bar.\n\n### The query bar\n\nAfter switching to ES|QL mode, the query bar shows your previous KQL or Lucene query converted into ES|QL. If the query was empty, it shows a sample query. For example:\n```esql\nFROM kibana_sample_data_logs | LIMIT 10\n```\n\nEvery query starts with a [source command](https://www.elastic.co/docs/reference/query-languages/esql/commands/source-commands). In this query, the source command is [`FROM`](https://www.elastic.co/docs/reference/query-languages/esql/commands/from). `FROM` retrieves data from data streams, indices, or aliases. In this example, the data is retrieved from `kibana_sample_data_logs`.\nA source command can be followed by one or more [processing commands](https://www.elastic.co/docs/reference/query-languages/esql/commands/processing-commands). In this query, the processing command is [`LIMIT`](https://www.elastic.co/docs/reference/query-languages/esql/commands/limit). `LIMIT` limits the number of rows that are retrieved.\n<tip>\n  Click the **ESQL help** button to open the in-product reference documentation for all commands and functions or to get recommended queries that will help you get started.\n\n\n\nThe ESQL editor supports [`LOOKUP JOIN`](https://www.elastic.co/docs/reference/query-languages/esql/commands/lookup-join) commands and suggests lookup mode indices and join condition fields.\n`stack: ga 9.2` You can also use lookup indices from your remote clusters.\n![Using the LOOKUP JOIN command to autocomplete an ES|QL query](https://images.contentstack.io/v3/assets/bltefdd0b53724fa2ce/blte43a30a93241d650/67c23670045f5839e5bfd1e4/lookup-join-demo.gif)\nIn **Discover**, LOOKUP JOIN commands let you create or edit lookup indices directly from the editor. Find more information in [Using ES|QL > Create and edit lookup indices from queries](/docs/explore-analyze/discover/try-esql#discover-esql-lookup-join).\n\n### Keyboard shortcuts\n\nThe ESQL editor supports several shortcuts to help you write and run your queries faster:\n\n| Mac           | Windows/Linux  | Description                 |\n|---------------|----------------|-----------------------------|\n| `Cmd + Enter` | `Ctrl + Enter` | Run a query                 |\n| `Cmd + /`     | `Ctrl + /`",
                            "summarized": true
                        },
                        {
                            "title": "ES",
                            "url": "https://www.elastic.co/docs/solutions/search/agent-builder/tools/esql-tools",
                            "content": "# ES|QL tools\n\nES|QL query tools enable you to create parameterized queries that execute directly against your Elasticsearch data. These custom tools provide precise control over data retrieval through templated [ES|QL](https://www.elastic.co/docs/reference/query-languages/esql) statements.\n\n## When to use ES|QL tools\n\nUse custom **ES|QL tools** when:\n- You need precise control over the query logic\n- Your use case involves repeatable analytical patterns\n- You want to expose specific, parameterized queries to agents\n- Results should be in a predictable tabular format\n- You have well-defined data retrieval requirements\n\n## Key characteristics\n\n- Execute pre-defined ES|QL queries with dynamic parameters\n- Support typed parameters\n- Return results in tabular format for structured data analysis\n- Ideal for repeatable analytical queries with variable inputs\n\n## Parameter types\n\nES|QL tools support the following parameter types:\n- **String types**: `text`, `keyword`\n- **Numeric types**: `long`, `integer`, `double`, `float`\n- **Other types**: `boolean`, `date`, `object`, `nested`\n\n## Parameter options\n\nParameters can be configured as:\n- **Required**: Must be provided by the agent when calling the tool\n- **Optional**: Can be omitted; uses `null` if no default is specified\n\n## Query syntax\n\nIn your ES|QL query, reference parameters using the `?parameter_name` syntax. The agent will automatically interpolate parameter values when executing the query.\n\n### Example\n\nHere's an example ES|QL tool that searches for books using full-text search. `?search_terms` is a named parameter that the agent will provide when executing the query.\n```esql\nFROM books\n| WHERE MATCH(title, ?search_terms)\n| KEEP title, author, year\n| LIMIT 10\n```\n\nYou can ask the LLM to infer the parameters for the query or add them manually.\n![Creating an ES|QL tool with a parameterized query](https://www.elastic.co/docs/solutions/search/agent-builder/images/create-esql-tool-query.png)\n\n## Best practices\n\n- **Include [`LIMIT`](https://www.elastic.co/docs/reference/query-languages/esql/commands/limit) clauses**: Prevent returning excessive results by setting reasonable limits\n- **Use meaningful parameter names**: Choose names that clearly indicate what the parameter represents (e.g., `start_date` instead of `date1`)\n- **Define parameter types**: Ensure parameters have the correct type to avoid runtime errors\n- **Provide clear descriptions**: Help agents understand when and how to use each parameter\n\n## Limitations\n\nES|QL tools are subject to the current limitations of the ES|QL language itself. For more information, refer to [ES|QL tool limitations](/docs/solutions/search/agent-builder/limitations-known-issues#esql-limitations).\n\n## ES|QL documentation\n\nTo learn more about the language, refer to the [ES|QL docs](https://www.elastic.co/docs/reference/query-languages/esql).",
                            "summarized": false
                        }
                    ]
                }
            }
        },
        {
            "@timestamp": "2026-01-10T09:58:12.685Z",
            "message": {
                "role": "assistant",
                "function_call": {
                    "name": "query",
                    "arguments": "",
                    "trigger": "assistant"
                },
                "content": ""
            }
        },
        {
            "@timestamp": "2026-01-10T09:58:15.709Z",
            "message": {
                "role": "user",
                "data": {
                    "keywords": [
                        "FROM",
                        "WHERE",
                        "STATS",
                        "SORT",
                        "LIMIT",
                        "EVAL",
                        "KEEP",
                        "MATCH",
                        "KQL",
                        "QSTR",
                        "CASE",
                        "DATE_PARSE",
                        "NOW",
                        "BUCKET"
                    ],
                    "requestedDocumentation": {
                        "FROM": "## FROM\n\nThe `FROM` command retrieves data from a data stream, index, or alias and returns it as a table. Each row in the table represents a document, and each column corresponds to a field that can be accessed by its name.\n\n## Syntax\n\n`FROM index_pattern [METADATA fields]`\n\n### Parameters\n\n#### `index_pattern`\n\nA list of indices, data streams, or aliases. Supports wildcards and date math.\n\n#### `fields`\n\nA comma-separated list of metadata fields to retrieve.\n\n## Examples\n\n### Basic Example\n\nRetrieve all documents from the `employees` index:\n\n```esql\nFROM employees\n```\n\n### Querying Multiple Data Streams, Indices, or Aliases\n\nQuery multiple data streams, indices, or aliases using a comma-separated list or wildcards:\n\n```esql\nFROM employees-00001,other-employees-*\n```\n\n### Querying Across Clusters\n\nQuery data streams and indices on remote clusters using the format `<remote_cluster_name>:<target>`:\n\n```esql\nFROM cluster_one:employees-00001,cluster_two:other-employees-*\n```\n\n### Using the `METADATA` Directive\n\nEnable metadata fields by using the optional `METADATA` directive:\n\n```esql\nFROM employees METADATA _id, _score\n```\n",
                        "WHERE": "## WHERE\n\nThe `WHERE` command filters rows from the input table, returning only those for which the specified condition evaluates to `true`.\n\n## Syntax\n\n`WHERE expression`\n\n### Parameters\n\n#### `expression`\n\nA boolean expression that determines which rows are included in the output.\n\n## Examples\n\n### Basic Usage\n\nFilter rows where the `still_hired` field is `true`:\n\n```esql\nFROM employees\n| KEEP first_name, last_name, still_hired\n| WHERE still_hired == true\n```\n\nIf `still_hired` is a boolean field, the query can be simplified to:\n\n```esql\nFROM employees\n| KEEP first_name, last_name, still_hired\n| WHERE still_hired\n```\n\n### Using Date Math\n\nRetrieve rows from the last hour of logs:\n\n```esql\nFROM sample_data\n| WHERE @timestamp > NOW() - 1 hour\n```\n\n### Using Functions\n\nFilter rows where the length of the `first_name` field is less than 4:\n\n```esql\nFROM employees\n| KEEP first_name, last_name, height\n| WHERE LENGTH(first_name) < 4\n```\n\n### NULL Comparison\n\nFilter rows where the `birth_date` field is `NULL`:\n\n```esql\nFROM employees\n| WHERE birth_date IS NULL\n| KEEP first_name, last_name\n| SORT first_name\n| LIMIT 3\n```\n\nFilter rows where the `is_rehired` field is not `NULL`:\n\n```esql\nFROM employees\n| WHERE is_rehired IS NOT NULL\n| STATS COUNT(emp_no)\n```\n\n### Using LIKE for String Patterns\n\nFilter rows based on string patterns using wildcards. The following wildcard characters are supported:\n- `*` matches zero or more characters.\n- `?` matches one character.\n\nFilter rows where `first_name` matches the pattern `?b*`:\n\n```esql\nFROM employees\n| WHERE first_name LIKE \"\"\"?b*\"\"\"\n| KEEP first_name, last_name\n```\n\nTo match the exact characters `*` or `.`, escape them using a backslash (`\\\\`). For example:\n\n```esql\nROW message = \"foo * bar\"\n| WHERE message LIKE \"foo \\\\* bar\"\n```\n\nTo simplify escaping, use triple-quoted strings:\n\n```esql\nROW message = \"foo * bar\"\n| WHERE message LIKE \"\"\"foo \\* bar\"\"\"\n```\n\n### Using RLIKE for Regular Expressions\n\nFilter rows based on regular expressions. For example, filter rows where `first_name` matches the pattern `.leja.*`:\n\n```esql\nFROM employees\n| WHERE first_name RLIKE \"\"\".leja.*\"\"\"\n| KEEP first_name, last_name\n```\n\nEscape special characters in regular expressions using a backslash (`\\\\`). For example:\n\n```esql\nROW message = \"foo ( bar\"\n| WHERE message RLIKE \"foo \\\\( bar\"\n```\n\nTo simplify escaping, use triple-quoted strings:\n\n```esql\nROW message = \"foo ( bar\"\n| WHERE message RLIKE \"\"\"foo \\( bar\"\"\"\n```\n\n### Using IN Operator\n\nFilter rows where an expression matches any value in a list of literals, fields, or expressions:\n\n```esql\nROW a = 1, b = 4, c = 3\n| WHERE c-a IN (3, b / 2, a)\n```",
                        "STATS": "# STATS\n\nThe `STATS` command groups rows based on a common value and calculates one or more aggregated values over the grouped rows.\n\n## Syntax\n\n`STATS [column1 =] expression1 [WHERE boolean_expression1][, ..., [columnN =] expressionN [WHERE boolean_expressionN]] [BY grouping_expression1[, ..., grouping_expressionN]]`\n\n### Parameters\n\n#### `columnX`\n\nThe name by which the aggregated value is returned. If omitted, the name defaults to the corresponding expression (`expressionX`). If multiple columns have the same name, all but the rightmost column with this name are ignored.\n\n#### `expressionX`\n\nAn expression that computes an aggregated value.\n\n#### `grouping_expressionX`\n\nAn expression that outputs the values to group by. If its name coincides with one of the computed columns, that column will be ignored.\n\n#### `boolean_expressionX`\n\nThe condition that must be met for a row to be included in the evaluation of `expressionX`.\n\n## Examples\n\n### Calculating a statistic and grouping by the values of another column\n\n```esql\nFROM employees\n| STATS count = COUNT(emp_no) BY languages\n| SORT languages\n```\n\nGroup rows by the `languages` column and calculate the count of `emp_no` for each group.\n\n### Omitting `BY` to return one row with the aggregations applied over the entire dataset\n\n```esql\nFROM employees\n| STATS avg_lang = AVG(languages)\n```\n\nCalculate the average number of languages across all rows.\n\n### Calculating multiple values\n\n```esql\nFROM employees\n| STATS avg_lang = AVG(languages), max_lang = MAX(languages)\n```\n\nCalculate both the average and maximum number of languages.\n\n### Filtering rows that go into an aggregation using `WHERE`\n\n```esql\nFROM employees\n| STATS avg50s = AVG(salary)::LONG WHERE birth_date < \"1960-01-01\"\n```\n\nGroup rows by `gender` and calculate the average salary for employees born before and after 1960.\n\n### Mixing aggregations with and without filters, and optional grouping\n\n```esql\nFROM employees\n| EVAL Ks = salary / 1000 // thousands\n| STATS under_40K = COUNT(*) WHERE Ks < 40, inbetween = COUNT(*) WHERE Ks >= 40 and Ks <= 60, over_60K = COUNT(*) WHERE Ks > 60, total = COUNT(*)\n```\n\nCalculate counts for salary ranges (under 40K, between 40K and 60K, over 60K) and the total count.\n\n### Grouping by a multivalued key\n\n```esql\nROW i=1, a=[\"a\", \"b\"]\n| STATS MIN(i) BY a\n| SORT a ASC\n```\n\nGroup rows by the multivalued column `a` and calculate the minimum value of `i` for each group.\n\n### Grouping by multiple values\n\n```esql\nFROM employees\n| EVAL hired = DATE_FORMAT(\"yyyy\", hire_date)\n| STATS avg_salary = AVG(salary) BY hired, languages.long\n| EVAL avg_salary = ROUND(avg_salary)\n| SORT hired, languages.long\n```\n\nGroup rows by the year of hire and the `languages.long` column, then calculate and round the average salary for each group.\n\n### Grouping by multiple multivalued keys\n\n```esql\nROW i=1, a=[\"a\", \"b\"], b=[2, 3]\n| STATS MIN(i) BY a, b\n| SORT a ASC, b ASC\n```\n\nGroup rows by the multivalued columns `a` and `b` and calculate the minimum value of `i` for each group.\n\n### Using functions in aggregating and grouping expressions\n\n```esql\nFROM employees\n| STATS avg_salary_change = ROUND(AVG(MV_AVG(salary_change)), 10)\n```\n\nCalculate the average salary change using the `MV_AVG` function and round the result to 10 decimal places.\n\n### Grouping by an expression\n\n```esql\nFROM employees\n| STATS my_count = COUNT() BY LEFT(last_name, 1)\n| SORT `LEFT(last_name, 1)`\n```\n\nGroup rows by the first letter of the `last_name` column and calculate the count for each group.\n\n### Specifying the output column name (optional)\n\n```esql\nFROM employees\n| STATS AVG(salary)\n```\n\nCalculate the average salary. The output column name defaults to `AVG(salary)`.\n\n### Using quoted column names in subsequent commands\n\n```esql\nFROM employees\n| STATS AVG(salary)\n| EVAL avg_salary_rounded = ROUND(`AVG(salary)`)\n```\n\nUse the calculated column `AVG(salary)` in subsequent commands by quoting its name.\n\n## Limitations\n\n- Individual `null` values are skipped when computing aggregations.\n- `STATS` without any groups is faster than adding a group.\n- Grouping on a single expression is more optimized than grouping on multiple expressions. For example, grouping on a single `keyword` column is significantly faster than grouping on two `keyword` columns.\n- Avoid combining columns with functions like `CONCAT` for grouping, as it does not improve performance.\n",
                        "SORT": "## SORT\n\nThe `SORT` command organizes a table by one or more columns.\n\n## Syntax\n\n`SORT column1 [ASC/DESC][NULLS FIRST/NULLS LAST][, ..., columnN [ASC/DESC][NULLS FIRST/NULLS LAST]]`\n\n### Parameters\n\n#### `columnX`\n\nThe column to sort on.\n\n## Examples\n\n### Basic sorting\n\nSort the table by the `height` column in ascending order (default behavior):\n\n```esql\nFROM employees\n| KEEP first_name, last_name, height\n| SORT height\n```\n\n### Explicitly sorting in descending order with `DESC`\n\nSort the table by the `height` column in descending order:\n\n```esql\nFROM employees\n| KEEP first_name, last_name, height\n| SORT height DESC\n```\n\n### Providing additional sort expressions to act as tie breakers\n\nSort the table by `height` in descending order, and use `first_name` in ascending order as a tie breaker:\n\n```esql\nFROM employees\n| KEEP first_name, last_name, height\n| SORT height DESC, first_name ASC\n```\n\n### Sorting `null` values first using `NULLS FIRST`\n\nSort the table by `first_name` in ascending order, placing `null` values first:\n\n```esql\nFROM employees\n| KEEP first_name, last_name, height\n| SORT first_name ASC NULLS FIRST\n```\n\n## Notes\n\nIf SORT is used right after a KEEP command, make sure it only uses column names in KEEP,\nor move the SORT before the KEEP, e.g.\n- not correct: KEEP date | SORT @timestamp,\n- correct: SORT @timestamp | KEEP date)\n\nBy default, the sorting order is ascending. You can specify an explicit sort order by using `ASC` for ascending or `DESC` for descending.\n\nIf two rows have the same sort key, they are considered equal. You can provide additional sort expressions to act as tie breakers.\n\nWhen sorting on multivalued columns, the lowest value is used when sorting in ascending order and the highest value is used when sorting in descending order.\n\nBy default, `null` values are treated as being larger than any other value. This means that with an ascending sort order, `null` values are sorted last, and with a descending sort order, `null` values are sorted first. You can change this by providing `NULLS FIRST` or `NULLS LAST`.\n\n## Limitations\n- **Multivalued Columns**: When sorting on multivalued columns, the lowest value is used for ascending order and the highest value for descending order.\n- **Null Values**: By default, null values are treated as larger than any other value. This can be changed using `NULLS FIRST` or `NULLS LAST`.\n",
                        "LIMIT": "## LIMIT\n\nThe `LIMIT` command restricts the number of rows returned by a query.\n\n## Syntax\n\n`LIMIT max_number_of_rows`\n\n### Parameters\n\n#### `max_number_of_rows`\n\nThe maximum number of rows to return.\n\n## Description\n\nThe `LIMIT` command restricts the number of rows returned by a query. For example:\n\n```esql\nFROM index\n| WHERE field == \"value\"\n| LIMIT 1000\n```\n\n## Examples\n\nLimit the result to the first 5 rows, sorted by `emp_no` in ascending order:\n\n```esql\nFROM employees\n| SORT emp_no ASC\n| LIMIT 5\n```\n\n## Limitations\n\n- Queries cannot return more than 10,000 rows, even if the `LIMIT` value exceeds this threshold.\n\nTo work around this limitation:\n  - Reduce the size of the result set by modifying the query to only return relevant data. This can be achieved by using the WHERE command to select a smaller subset of the data.\n  - Shift any post-query processing to the query itself. The ES|QL STATS ... BY command can be used to aggregate data within the query.\n\n",
                        "EVAL": "# EVAL\n\nThe `EVAL` command allows you to add new columns with calculated values to your dataset.\n\n## Syntax\n\n`EVAL [column1 =] value1[, ..., [columnN =] valueN]`\n\n### Parameters\n\n#### `columnX`\n\n- The name of the column to be added or updated.\n- If a column with the same name already exists, it will be replaced by the new column.\n- If a column name is used multiple times, only the rightmost definition is applied.\n\n#### `valueX`\n\n- The value to assign to the column. This can be a literal, an expression, or a function.\n- You can reference columns defined earlier in the same `EVAL` command.\n\n## Notes\n\nEVAL supports the following types of functions:\n- Mathematical functions\n- String functions\n- Date-time functions\n- Type conversation functions\n- Conditional functions and expressions\n- Multi-value functions\n\nAggregation functions are NOT supported for EVAL.\n\n## Examples\n\n### Adding new calculated columns\n\nAdd two new columns, `height_feet` and `height_cm`, by performing calculations on the `height` column:\n\n```esql\nFROM employees\n| SORT emp_no\n| KEEP first_name, last_name, height\n| EVAL height_feet = height * 3.281, height_cm = height * 100\n```\n\n### Overwriting an existing column\n\nReplace the `height` column with a new value calculated by converting it to feet:\n\n```esql\nFROM employees\n| SORT emp_no\n| KEEP first_name, last_name, height\n| EVAL height = height * 3.281\n```\n\n### Adding a column without specifying a name\n\nIf no column name is provided, the new column will be named after the expression itself. For example, this query adds a column named `height*3.281`:\n\n```esql\nFROM employees\n| SORT emp_no\n| KEEP first_name, last_name, height\n| EVAL height * 3.281\n```\n\n### Using a column with special characters in subsequent commands\n\nWhen a column name contains special characters, enclose it in backticks (`) to reference it in later commands:\n\n```esql\nFROM employees\n| EVAL height * 3.281\n| STATS avg_height_feet = AVG(`height * 3.281`)\n```\n\nAny number of evaluations can be performed in a single EVAL command\n\n```esql\nFROM triangle\n| EVAL cos = COS(angle), tan = TAN(angle), sin = SIN(angle), acos=ACOS(angle), asin=ASIN(angle)\n| SORT angle DESC\n| LIMIT 10\n```\n\n### Limitations\n- If a column with the same name already exists, the existing column is dropped.\n- If a column name is used more than once, only the rightmost duplicate creates a column.\n",
                        "KEEP": "## KEEP\n\nThe `KEEP` command specifies which columns are returned and the order in which they appear in the output.\n\n## Syntax\n\n`KEEP columns`\n\n### Parameters\n\n#### `columns`\n\nA comma-separated list of columns to retain. Supports wildcards. If a column matches multiple expressions, precedence rules determine the final output.\n\n## Note\n\nThe KEEP command is used to specify which columns to return and their order.\n\nWhen a field name matches multiple expressions, precedence rules are applied. Fields are added in the order they appear. If one field matches multiple expressions, the following precedence rules apply (from highest to lowest priority):\n\n1. Complete field name (without wildcards)\n2. Partial wildcard expressions (like `fieldNam*`)\n3. Only wildcard (`*`)\n\nIf a field matches two expressions with the same precedence, the rightmost expression wins.\n\nImportant: only the columns in the KEEP command can be used after a KEEP command.\n\n## Examples\n\n### Return columns in a specific order\n\nThe following query returns the `emp_no`, `first_name`, `last_name`, and `height` columns in the specified order:\n\n```esql\nFROM employees\n| KEEP emp_no, first_name, last_name, height\n```\n\n### Use wildcards to match column names\n\nThis query keeps all columns with names starting with `h`:\n\n```esql\nFROM employees\n| KEEP h*\n```\n\n### Combine specific columns and wildcards\n\nThe asterisk wildcard (`*`) matches all columns not explicitly specified. This query returns all columns starting with `h` first, followed by all other columns:\n\n```esql\nFROM employees\n| KEEP h*, *\n```\n\n### Precedence of complete field names over wildcards\n\nWhen a column matches both a complete field name and a wildcard, the complete field name takes precedence:\n\n```esql\nFROM employees\n| KEEP first_name, last_name, first_name*\n```\n\n### Wildcard precedence and ordering\n\nIf a column matches multiple wildcard expressions, the rightmost expression takes precedence, even if it is less specific:\n\n```esql\nFROM employees\n| KEEP first_name*, last_name, first_na*\n```\n\n### Lowest precedence for the `*` wildcard\n\nThe `*` wildcard has the lowest precedence. The order of other arguments determines the output order:\n\n```esql\nFROM employees\n| KEEP *, first_name\n```\n",
                        "MATCH": "# MATCH\n\nThe `MATCH` function performs a match query on the specified field. It is equivalent to the `match` query in the Elasticsearch Query DSL and can be used to search for values in various field types, including text, semantic_text, keyword, boolean, dates, and numeric types.\n\n`MATCH` supports function named parameters to specify additional options for the match query. For a simplified syntax, the match operator `:` can be used instead of `MATCH`. The function returns `true` if the provided query matches the row.\n\n## Syntax\n\n`MATCH(field, query, options)`\n\n### Parameters\n\n#### `field`\n\nThe field that the query will target.\n\n#### `query`\n\nThe value to find in the specified field.\n\n#### `options`\n\n(Optional) Additional match query options provided as function named parameters. Refer to the match query documentation for more details.\n\n## Examples\n\nMatch on a specific field\n\n```esql\nFROM books\n| WHERE MATCH(author, \"Faulkner\")\n| KEEP book_no, author\n| SORT book_no\n| LIMIT 5\n```\n\nThis example retrieves books where the `author` field matches \"Faulkner,\" keeping only the `book_no` and `author` fields, sorting by `book_no`, and limiting the results to 5 rows.\n\nMatch with additional options\n\n```esql\nFROM books\n| WHERE MATCH(title, \"Hobbit Back Again\", {\"operator\": \"AND\"})\n| KEEP title\n```\n\nThis example searches for books where the `title` field matches \"Hobbit Back Again\" using the `AND` operator, and keeps only the `title` field in the results.\n\nMatch with sorting on score\n\nMatch on a specific field\n\n```esql\nFROM books METADATA _score\n| WHERE MATCH(author, \"Faulkner\")\n| SORT _score DESC\n| KEEP book_no, author\n| LIMIT 5\n```\n",
                        "KQL": "## KQL\n\nPerforms a KQL query and returns `true` if the provided KQL query string matches the row.\n\n## Syntax\n\n`KQL(query)`\n\n### Parameters\n\n#### `query`\n\nQuery string in KQL query string format.\n\n## Examples\n\n```esql\nFROM books\n| WHERE KQL(\"author: Faulkner\")\n| KEEP book_no, author\n| SORT book_no\n| LIMIT 5\n```\n\nThis example filters rows where the `author` field matches \"Faulkner,\" keeps the `book_no` and `author` columns, sorts the results by `book_no`, and limits the output to 5 rows.",
                        "QSTR": "## QSTR\n\nPerforms a query string query and returns `true` if the provided query string matches the row.\n\n## Syntax\n\n`QSTR(query)`\n\n### Parameters\n\n#### `query`\n\nQuery string in Lucene query string format.\n\n## Examples\n\n```esql\nFROM books\n| WHERE QSTR(\"author: Faulkner\")\n| KEEP book_no, author\n| SORT book_no\n| LIMIT 5\n```\n\nThis example filters rows where the `author` field matches \"Faulkner,\" keeps the `book_no` and `author` columns, sorts by `book_no`, and limits the output to 5 rows.",
                        "CASE": "## CASE\n\nThe `CASE` function evaluates a series of conditions and returns a value corresponding to the first condition that evaluates to `true`. If no conditions match, a default value or `null` is returned.\n\n## Syntax\n\n`CASE (condition, trueValue, elseValue)`\n\n### Parameters\n\n#### `condition`\n\nA condition to evaluate.\n\n#### `trueValue`\n\nThe value returned when the corresponding condition is the first to evaluate to `true`. If no condition matches, the default value is returned.\n\n#### `elseValue`\n\nThe value returned when no condition evaluates to `true`.\n\n## Examples\n\n### Determine whether employees are monolingual, bilingual, or polyglot\n\nClassify employees based on the number of languages they speak:\n\n```esql\nFROM employees\n| EVAL type = CASE(\n    languages <= 1, \"monolingual\",\n    languages <= 2, \"bilingual\",\n    \"polyglot\")\n| KEEP emp_no, languages, type\n```\n\n### Calculate the total connection success rate based on log messages\n\nDetermine the success rate of connections by analyzing log messages:\n\n```esql\nFROM sample_data\n| EVAL successful = CASE(\n    STARTS_WITH(message, \"Connected to\"), 1,\n    message == \"Connection error\", 0\n  )\n| STATS success_rate = AVG(successful)\n```\n\n### Calculate an hourly error rate as a percentage of the total number of log messages\n\nCompute the error rate for each hour based on log messages:\n\n```esql\nFROM sample_data\n| EVAL error = CASE(message LIKE \"*error*\", 1, 0)\n| EVAL hour = DATE_TRUNC(1 hour, @timestamp)\n| STATS error_rate = AVG(error) BY hour\n| SORT hour\n```\n",
                        "DATE_PARSE": "# DATE_PARSE\n\nParses a date string into a date object using the specified format.\n\n## Syntax\n\n`DATE_PARSE(datePattern, dateString)`\n\n### Parameters\n\n#### `datePattern`\n\nThe date format. Refer to the `DateTimeFormatter` documentation for the syntax. If `null`, the function returns `null`.\n\n#### `dateString`\n\nA date expression as a string. If `null` or an empty string, the function returns `null`.\n\n## Examples\n\nParsing a date string\n\n```esql\nROW date_string = \"2022-05-06\"\n| EVAL date = DATE_PARSE(\"yyyy-MM-dd\", date_string)\n```\n\nThis example parses the string `\"2022-05-06\"` into a date object using the format `\"yyyy-MM-dd\"`.\n",
                        "NOW": "## NOW\n\nReturns the current date and time.\n\n## Syntax\n\n`NOW()`\n\n### Parameters\n\nThis function does not take any parameters.\n\n## Examples\n\n#Retrieve the current date and time\n\n```esql\nROW current_date = NOW()\n```\n\n#Retrieve logs from the last hour\n\n```esql\nFROM sample_data\n| WHERE @timestamp > NOW() - 1 hour\n```\n",
                        "BUCKET": "# BUCKET\n\nThe `BUCKET` function creates groups of valuesbucketsout of a datetime or numeric input. The size of the buckets can either be provided directly or chosen based on a recommended count and values range.\n\n## Syntax\n\n`BUCKET(field, buckets, from, to)`\n\n### Parameters\n\n#### `field`\n\nA numeric or date expression from which to derive buckets.\n\n#### `buckets`\n\nThe target number of buckets or the desired bucket size if the `from` and `to` parameters are omitted.\n\n#### `from` (optional)\n\nThe start of the range. Can be a number, a date, or a date expressed as a string.\n\n#### `to` (optional)\n\nThe end of the range. Can be a number, a date, or a date expressed as a string.\n\n## Important notes:\n\nBUCKET can operate in two modes:\n- one where the bucket size is computed based on a bucket count recommendation and a range,\n- and another where the bucket size is provided directly.\n\nWhen the bucket size is provided directly for time interval, it is expressed as a **timespan literal**, e.g.\n- GOOD: `BUCKET(@timestamp, 1 month)`\n- BAD: `BUCKET(@timestamp, \"month\")`\n\n## Examples\n\nUsing a target number of buckets, a start of a range, and an end of a range\n\n```esql\nFROM employees\n| WHERE hire_date >= \"1985-01-01T00:00:00Z\" AND hire_date < \"1986-01-01T00:00:00Z\"\n| STATS hire_date = MV_SORT(VALUES(hire_date)) BY month = BUCKET(hire_date, 20, \"1985-01-01T00:00:00Z\", \"1986-01-01T00:00:00Z\")\n| SORT hire_date\n```\n\nThis example creates buckets for hire dates in 1985, aiming for 20 buckets. The actual number of buckets may vary depending on the range.\n\nCombine BUCKET with an aggregation to create a histogram\n\n```esql\nFROM employees\n| WHERE hire_date >= \"1985-01-01T00:00:00Z\" AND hire_date < \"1986-01-01T00:00:00Z\"\n| STATS hires_per_month = COUNT(*) BY month = BUCKET(hire_date, 20, \"1985-01-01T00:00:00Z\", \"1986-01-01T00:00:00Z\")\n| SORT month\n```\n\nThis example calculates the number of hires per month in 1985.\n\nAsking for more buckets can result in a smaller range\n\n```esql\nFROM employees\n| WHERE hire_date >= \"1985-01-01T00:00:00Z\" AND hire_date < \"1986-01-01T00:00:00Z\"\n| STATS hires_per_week = COUNT(*) BY week = BUCKET(hire_date, 100, \"1985-01-01T00:00:00Z\", \"1986-01-01T00:00:00Z\")\n| SORT week\n```\n\nThis example creates weekly buckets for hire dates in 1985, aiming for 100 buckets.\n\nProviding the bucket size directly\n\n```esql\nFROM employees\n| WHERE hire_date >= \"1985-01-01T00:00:00Z\" AND hire_date < \"1986-01-01T00:00:00Z\"\n| STATS hires_per_week = COUNT(*) BY week = BUCKET(hire_date, 1 week)\n| SORT week\n```\n\nThis example creates weekly buckets for hire dates in 1985 by directly specifying the bucket size.\n\nCreating a salary histogram\n\n```esql\nFROM employees\n| STATS COUNT(*) BY bs = BUCKET(salary, 20, 25324, 74999)\n| SORT bs\n```\n\nThis example creates a histogram of salaries, dividing the range into 20 buckets.\n\nOmitting the range when the bucket size is known\n\n```esql\nFROM employees\n| WHERE hire_date >= \"1985-01-01T00:00:00Z\" AND hire_date < \"1986-01-01T00:00:00Z\"\n| STATS c = COUNT(*) BY b = BUCKET(salary, 5000.)\n| SORT b\n```\n\nThis example creates salary buckets with a fixed size of 5000.\n\nCreate hourly buckets for the last 24 hours\n\n```esql\nFROM sample_data\n| WHERE @timestamp >= NOW() - 1 day AND @timestamp < NOW()\n| STATS COUNT(*) BY bucket = BUCKET(@timestamp, 25, NOW() - 1 day, NOW())\n```\n\nThis example creates hourly buckets for the last 24 hours.\n\nCreate monthly buckets for the year 1985\n\n```esql\nFROM employees\n| WHERE hire_date >= \"1985-01-01T00:00:00Z\" AND hire_date < \"1986-01-01T00:00:00Z\"\n| STATS AVG(salary) BY bucket = BUCKET(hire_date, 20, \"1985-01-01T00:00:00Z\", \"1986-01-01T00:00:00Z\")\n| SORT bucket\n```\n\nThis example calculates the average salary for each month in 1985.\n\nUsing BUCKET in both aggregating and grouping parts of STATS\n\n```esql\nFROM employees\n| STATS s1 = b1 + 1, s2 = BUCKET(salary / 1000 + 999, 50.) + 2 BY b1 = BUCKET(salary / 100 + 99, 50.), b2 = BUCKET(salary / 1000 + 999, 50.)\n| SORT b1, b2\n| KEEP s1, b1, s2, b2\n```\n\nThis example demonstrates advanced usage of `BUCKET` in both aggregation and grouping.\n\nAdjusting bucket start value with an offset\n\n```esql\nFROM employees\n| STATS dates = MV_SORT(VALUES(birth_date)) BY b = BUCKET(birth_date + 1 HOUR, 1 YEAR) - 1 HOUR\n| EVAL d_count = MV_COUNT(dates)\n| SORT d_count, b\n| LIMIT 3\n```\n\nThis example adjusts the bucket start value by adding and subtracting an offset.\n"
                    }
                },
                "name": "query",
                "content": {}
            }
        },
        {
            "@timestamp": "2026-01-10T09:58:29.210Z",
            "message": {
                "role": "assistant",
                "content": "# The Difference Between KQL and ES|QL\n\nKQL (Kibana Query Language) and ES|QL (Elasticsearch Query Language) are both query languages used in the Elastic Stack, but they serve different purposes and have distinct capabilities.\n\n## KQL (Kibana Query Language)\n\nKQL is a simple, user-friendly query language designed primarily for filtering data in Kibana:\n\n- **Purpose**: Primarily used for filtering documents in Kibana's Discover, Visualize, and Dashboard applications\n- **Syntax**: Simple, concise syntax focused on field-value pairs and boolean operators\n- **Example**: `status:error AND host.name:webserver-*`\n- **Capabilities**: \n  - Basic filtering with field:value pairs\n  - Boolean operators (AND, OR, NOT)\n  - Range queries (e.g., `bytes > 1000`)\n  - Wildcard matching\n  - Nested field support\n- **Limitations**:\n  - Cannot perform aggregations or transformations\n  - Limited to filtering operations\n  - No data manipulation capabilities\n\n## ES|QL (Elasticsearch Query Language)\n\nES|QL is a comprehensive SQL-like language for querying, filtering, transforming, and analyzing data in Elasticsearch:\n\n- **Purpose**: Complete data processing pipeline language for querying, filtering, transforming, and analyzing data\n- **Syntax**: SQL-like with pipes (`|`) connecting commands in a processing pipeline\n- **Example**:\n  ```esql\nFROM logs\n| WHERE level == \"ERROR\"\n| STATS count = COUNT(*) BY host.name\n| SORT count DESC\n| LIMIT 10\n```\n- **Capabilities**:\n  - Data source selection with `FROM`\n  - Filtering with `WHERE`\n  - Aggregations with `STATS`\n  - Data transformation with `EVAL`\n  - Column selection with `KEEP`\n  - Sorting with `SORT`\n  - Full-text search with `MATCH`, `QSTR`, and `KQL` functions\n  - Date/time manipulation\n  - Mathematical operations\n  - String processing\n  - Spatial functions\n  - Multi-value field handling\n- **Integration**: ES|QL can actually use KQL within it via the `KQL()` function\n\n## Key Differences\n\n1. **Scope**: \n   - KQL is focused on filtering documents\n   - ES|QL provides a complete data processing pipeline\n\n2. **Power and Complexity**:\n   - KQL is simpler and easier to learn\n   - ES|QL is more powerful but has a steeper learning curve\n\n3. **Use Cases**:\n   - KQL: Quick filtering in Kibana UI\n   - ES|QL: Complex data analysis, transformations, and aggregations\n\n4. **Relationship**:\n   - ES|QL can actually incorporate KQL queries using the `KQL()` function\n   - ES|QL is the more comprehensive language that can do everything KQL can do and much more\n\n5. **Integration**:\n   - KQL is primarily used in Kibana's UI\n   - ES|QL is integrated across Elastic solutions including Observability, Security, and Search\n\nIn summary, KQL is a simple filtering language for quick searches in Kibana, while ES|QL is a comprehensive data processing language that provides SQL-like capabilities for complex querying, transformation, and analysis of data in Elasticsearch."
            }
        }
    ]
}